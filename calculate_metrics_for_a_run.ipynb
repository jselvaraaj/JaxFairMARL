{
 "cells": [
  {
   "cell_type": "code",
   "id": "a03d32b1ca9a396f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:30.698384Z",
     "start_time": "2025-01-31T21:10:30.686968Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8b024d1e9cfcad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:33.127422Z",
     "start_time": "2025-01-31T21:10:30.719852Z"
    }
   },
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from calculate_metric import get_stats_for_state\n",
    "from visualize_actor import get_state_traj\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:43.082258Z",
     "start_time": "2025-01-31T21:10:33.219473Z"
    }
   },
   "source": [
    "artifact_version = \"530\"\n",
    "num_episodes = 100\n",
    "model_artifact_remote_name = (\n",
    "    f\"josssdan/JaxInforMARL/PPO_RNN_Runner_State:v{artifact_version}\"\n",
    ")\n",
    "\n",
    "traj_batch, config, env = get_state_traj(model_artifact_remote_name, artifact_version, num_episodes=num_episodes,\n",
    "                                         store_action_field=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   10 of 10 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'derived_values': {'minibatch_size': 19200,\n",
      "                    'num_actors': 300,\n",
      "                    'num_updates': 39,\n",
      "                    'scaled_clip_eps': 0.2},\n",
      " 'env_config': {'env_cls_name': 'StackedTargetMPEEnvironment',\n",
      "                'env_kwargs': {'add_self_edges_to_nodes': True,\n",
      "                               'agent_communication_type': None,\n",
      "                               'agent_control_noise_std': 0.0,\n",
      "                               'agent_max_speed': -1,\n",
      "                               'agent_previous_obs_stack_size': 3,\n",
      "                               'agent_visibility_radius': [0.25],\n",
      "                               'collision_reward_coefficient': -1,\n",
      "                               'distance_to_goal_reward_coefficient': 10,\n",
      "                               'entities_initial_coord_radius': [1],\n",
      "                               'entity_acceleration': 5,\n",
      "                               'max_steps': 100,\n",
      "                               'num_agents': 3,\n",
      "                               'one_time_death_reward': 5}},\n",
      " 'network_config': {'actor_num_hidden_linear_layer': 2,\n",
      "                    'critic_num_hidden_linear_layer': 2,\n",
      "                    'entity_type_embedding_dim': 4,\n",
      "                    'fc_dim_size': 64,\n",
      "                    'graph_attention_key_dim': 16,\n",
      "                    'graph_hidden_feature_dim': 16,\n",
      "                    'graph_num_linear_layer': 2,\n",
      "                    'gru_hidden_dim': 64,\n",
      "                    'node_hidden_dim': 16,\n",
      "                    'node_num_layers': 2,\n",
      "                    'num_graph_attn_layers': 2,\n",
      "                    'num_heads_per_attn_layer': 3},\n",
      " 'training_config': {'anneal_lr': True,\n",
      "                     'gamma': 0.99,\n",
      "                     'lr': 0.0005,\n",
      "                     'num_envs': 100,\n",
      "                     'num_seeds': 2,\n",
      "                     'ppo_config': {'clip_eps': 0.2,\n",
      "                                    'entropy_coefficient': 0.01,\n",
      "                                    'gae_lambda': 0.95,\n",
      "                                    'is_clip_eps_per_env': False,\n",
      "                                    'max_grad_norm': 10,\n",
      "                                    'num_minibatches_actors': 4,\n",
      "                                    'num_steps_per_update': 256,\n",
      "                                    'update_epochs': 4,\n",
      "                                    'value_coefficient': 0.5},\n",
      "                     'seed': 65,\n",
      "                     'total_timesteps': 1000000.0},\n",
      " 'wandb_config': {'checkpoint_model_every_update_steps': 1000000.0,\n",
      "                  'entity': 'josssdan',\n",
      "                  'mode': 'online',\n",
      "                  'project': 'JaxInforMARL',\n",
      "                  'save_model': True}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "243953c079fafd50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:46.092362Z",
     "start_time": "2025-01-31T21:10:46.066425Z"
    }
   },
   "source": [
    "num_envs = config.training_config.num_envs\n",
    "num_agents = config.env_config.env_kwargs.num_agents\n",
    "num_steps = config.env_config.env_kwargs.max_steps"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "be320bcf7a38ca12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:47.000241Z",
     "start_time": "2025-01-31T21:10:46.140873Z"
    }
   },
   "source": [
    "# reshaping so that the axis becomes num_env, num_steps, num_agents...\n",
    "\n",
    "traj_batch = jax.tree.map(lambda x: x.reshape(num_steps, num_agents, num_envs, *x.shape[2:]), traj_batch)\n",
    "traj_batch = jax.tree.map(\n",
    "    lambda x: jnp.swapaxes(x, 1, 2),\n",
    "    traj_batch,\n",
    ")\n",
    "traj_batch = jax.tree.map(\n",
    "    lambda x: jnp.swapaxes(x, 0, 1),\n",
    "    traj_batch,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "c14560665810f9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:47.286979Z",
     "start_time": "2025-01-31T21:10:47.261742Z"
    }
   },
   "source": [
    "jax.tree.map(lambda x: x.shape, traj_batch)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransitionForVisualization(global_done=(100, 100, 3), done=(100, 100, 3), action=(100, 100, 3), value=(100, 100, 3), reward=(100, 100, 3), log_prob=(100, 100, 3), obs=(100, 100, 3, 18), graph=GraphsTupleWithAgentIndex(nodes=(100, 100, 3, 6, 21), edges=(100, 100, 3, 21, 1), receivers=(100, 100, 3, 21), senders=(100, 100, 3, 21), globals=None, n_node=(100, 100, 3), n_edge=(100, 100, 3), agent_indices=(100, 100, 3)), world_state=(100, 100, 3, 54), info={'returned_episode': (100, 100, 3), 'returned_episode_lengths': (100, 100, 3), 'returned_episode_returns': (100, 100, 3)}, env_state=LogEnvState(env_state=MPEStateWithBuffer(dones=(100, 100, 3, 3), step=(100, 100, 3), entity_positions=(100, 100, 3, 6, 2), entity_velocities=(100, 100, 3, 6, 2), did_agent_die_this_time_step=(100, 100, 3, 3), agent_communication_message=(100, 100, 3, 0), agent_visibility_radius=(100, 100, 3, 3), obs_buffer={'agent_0': (100, 100, 3, 6, 3), 'agent_1': (100, 100, 3, 6, 3), 'agent_2': (100, 100, 3, 6, 3)}, nodes_buffer={'agent_0': (100, 100, 3, 6, 7, 3), 'agent_1': (100, 100, 3, 6, 7, 3), 'agent_2': (100, 100, 3, 6, 7, 3)}), episode_returns=(100, 100, 3, 3), episode_lengths=(100, 100, 3, 3), returned_episode_returns=(100, 100, 3, 3), returned_episode_lengths=(100, 100, 3, 3)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "5825d20a7ead14fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:47.486129Z",
     "start_time": "2025-01-31T21:10:47.422899Z"
    }
   },
   "source": [
    "# summing across all steps in episode and across all agents\n",
    "total_reward = jnp.sum(traj_batch.reward, axis=(1, 2))\n",
    "avg_reward_per_episode = jnp.average(total_reward).item()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e4dbf6617c2c421c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:47.752588Z",
     "start_time": "2025-01-31T21:10:47.728762Z"
    }
   },
   "source": [
    "avg_reward_per_episode"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4458.63525390625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a86b2b58613252a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:48.131227Z",
     "start_time": "2025-01-31T21:10:47.891336Z"
    }
   },
   "source": [
    "done = jnp.swapaxes(traj_batch.done, 1, 2)  # so that it becomes num_env, num_agents, num_steps\n",
    "avg_goal_reach_time_in_episode_fraction = (jnp.argmax(done, axis=-1) + 1) / num_steps\n",
    "agents_that_didnt_reach_goal = jnp.all(~done, axis=-1)\n",
    "avg_goal_reach_time_in_episode_fraction = avg_goal_reach_time_in_episode_fraction.at[agents_that_didnt_reach_goal].set(\n",
    "    1)\n",
    "avg_goal_reach_time_in_episode_fraction = jnp.average(avg_goal_reach_time_in_episode_fraction).item()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "59382adea20bab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:48.424418Z",
     "start_time": "2025-01-31T21:10:48.400578Z"
    }
   },
   "source": [
    "avg_goal_reach_time_in_episode_fraction"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12413332611322403"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "ec21d308c41dda7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:48.664549Z",
     "start_time": "2025-01-31T21:10:48.560598Z"
    }
   },
   "source": [
    "reached_goal = jnp.any(done, axis=-1)\n",
    "all_agents_reached_goal = jnp.all(reached_goal, axis=-1)\n",
    "\n",
    "episode_percent_all_agents_reached_goals = jnp.average(all_agents_reached_goal) * 100\n",
    "episode_percent_all_agents_reached_goals = episode_percent_all_agents_reached_goals.item()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "e5055b7e305080ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:48.824275Z",
     "start_time": "2025-01-31T21:10:48.800945Z"
    }
   },
   "source": [
    "episode_percent_all_agents_reached_goals"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "9ce79b5e0ff9a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:49.113253Z",
     "start_time": "2025-01-31T21:10:49.089906Z"
    }
   },
   "source": [
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def compute_stats_for_all_episode(env, state):\n",
    "    compute_stats_for_every_step = jax.vmap(get_stats_for_state, in_axes=(None, 0))\n",
    "    compute_all_stats = jax.vmap(compute_stats_for_every_step, in_axes=(None, 0))\n",
    "    return compute_all_stats(env, state)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "d73db91942908241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:49.531939Z",
     "start_time": "2025-01-31T21:10:49.251621Z"
    }
   },
   "source": [
    "env_state = traj_batch.env_state.env_state\n",
    "env_state = jax.tree.map(lambda x: x[:, :, 0],\n",
    "                         env_state)  # take state from one agent since it will be the same for all agents"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "8463dc1c85054829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:49.924190Z",
     "start_time": "2025-01-31T21:10:49.836798Z"
    }
   },
   "source": [
    "num_collisions, num_agent_died = compute_stats_for_all_episode(env, env_state)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "57a3ae75722ef040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:50.165826Z",
     "start_time": "2025-01-31T21:10:50.099239Z"
    }
   },
   "source": [
    "avg_num_collision_across_all_episodes = jnp.average(num_collisions).item()\n",
    "avg_num_deaths_across_all_episodes = jnp.average(num_agent_died).item()"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "224b5df8a8442adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:50.492228Z",
     "start_time": "2025-01-31T21:10:50.468092Z"
    }
   },
   "source": [
    "avg_reward_per_episode, avg_goal_reach_time_in_episode_fraction, f\"{episode_percent_all_agents_reached_goals} %\", avg_num_collision_across_all_episodes"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4458.63525390625, 0.12413332611322403, '100.0 %', 0.08654999732971191)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "a246ec7702a46aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:10:50.683162Z",
     "start_time": "2025-01-31T21:10:50.660223Z"
    }
   },
   "source": [
    "(-4745.63916015625, 0.11216667294502258, '100.0 %', 0.09730000048875809)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4745.63916015625, 0.11216667294502258, '100.0 %', 0.09730000048875809)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InforMARLJAX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
